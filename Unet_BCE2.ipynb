{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f800ba",
   "metadata": {
    "id": "b24062f3"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d479ac",
   "metadata": {
    "id": "056898e6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005dd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sources:\n",
    "#https://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370293d7",
   "metadata": {
    "id": "4b49e307"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './dataset'\n",
    "\n",
    "x_train_dir = os.path.join(DATA_DIR, 'x_train')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'y_train')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'x_val')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'y_val')\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'x_test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'y_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c20c5",
   "metadata": {
    "id": "92cce050"
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a3a81e",
   "metadata": {
    "id": "6ff1c2fc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102765f",
   "metadata": {
    "id": "64688448"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_cadis_colormap():\n",
    "    \"\"\"\n",
    "    Returns cadis colormap as in paper\n",
    "    :return: ndarray of rgb colors\n",
    "    \"\"\"\n",
    "    return np.asarray(\n",
    "        [\n",
    "            [0, 137, 255],\n",
    "            [255, 165, 0],\n",
    "            [255, 156, 201],\n",
    "            [99, 0, 255],\n",
    "            [255, 0, 0],\n",
    "            [255, 0, 165],\n",
    "            [255, 255, 255],\n",
    "            [141, 141, 141],\n",
    "            [255, 218, 0],\n",
    "            [173, 156, 255],\n",
    "            [73, 73, 73],\n",
    "            [250, 213, 255],\n",
    "            [255, 156, 156],\n",
    "            [99, 255, 0],\n",
    "            [157, 225, 255],\n",
    "            [255, 89, 124],\n",
    "            [173, 255, 156],\n",
    "            [255, 60, 0],\n",
    "            [40, 0, 255],\n",
    "            [170, 124, 0],\n",
    "            [188, 255, 0],\n",
    "            [0, 207, 255],\n",
    "            [0, 255, 207],\n",
    "            [188, 0, 255],\n",
    "            [243, 0, 255],\n",
    "            [0, 203, 108],\n",
    "            [252, 255, 0],\n",
    "            [93, 182, 177],\n",
    "            [0, 81, 203],\n",
    "            [211, 183, 120],\n",
    "            [231, 203, 0],\n",
    "            [0, 124, 255],\n",
    "            [10, 91, 44],\n",
    "            [2, 0, 60],\n",
    "            [0, 144, 2],\n",
    "            [133, 59, 59],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def remap_mask(mask, class_remapping, ignore_label=255):\n",
    "    \"\"\"\n",
    "    Remaps mask class ids\n",
    "    :param mask: 2D/3D ndarray of input segmentation mask\n",
    "    :param class_remapping: dictionary that indicates class remapping\n",
    "    :param ignore_label: class ids to be ignored\n",
    "    :return: 2D/3D ndarray of remapped segmentation mask\n",
    "    \"\"\"\n",
    "    classes = []\n",
    "    for key, val in class_remapping.items():\n",
    "        for cls in val:\n",
    "            classes.append(cls)\n",
    "    assert len(classes) == len(set(classes))\n",
    "\n",
    "    N = max(len(classes), mask.max() + 1)\n",
    "    remap_array = np.full(N, ignore_label, dtype=np.uint8)\n",
    "    for key, val in class_remapping.items():\n",
    "        for v in val:\n",
    "            remap_array[v] = key\n",
    "    return remap_array[mask]\n",
    "\n",
    "\n",
    "def get_remapped_colormap(class_remapping):\n",
    "    \"\"\"\n",
    "    Generated colormap of remapped classes\n",
    "    Classes that are not remapped are indicated by the same color across all experiments\n",
    "    :param class_remapping: dictionary that indicates class remapping\n",
    "    :return: 2D ndarray of rgb colors for remapped colormap\n",
    "    \"\"\"\n",
    "    colormap = get_cadis_colormap()\n",
    "    remapped_colormap = {}\n",
    "    for key, val in class_remapping.items():\n",
    "        if key == 255:\n",
    "            remapped_colormap.update({key: [0, 0, 0]})\n",
    "        else:\n",
    "            remapped_colormap.update({key: colormap[val[0]]})\n",
    "    return remapped_colormap\n",
    "\n",
    "\n",
    "def mask_to_colormap(mask, colormap):\n",
    "    \"\"\"\n",
    "    Genarates RGB mask colormap from mask with class ids\n",
    "    :param mask: 2D/3D ndarray of input segmentation mask\n",
    "    :param colormap: dictionary that indicates color corresponding to each class\n",
    "    :return: 3D ndarray Generated RGB mask\n",
    "    \"\"\"\n",
    "    rgb = np.zeros(mask.shape[:2] + (3,), dtype=np.uint8)\n",
    "    for label, color in colormap.items():\n",
    "        rgb[mask == label] = color\n",
    "    return rgb\n",
    "\n",
    "\n",
    "def plot_images(img, remapped_mask, remapped_colormap, classes_exp):\n",
    "    \"\"\"\n",
    "    Generates plot of Image and RGB mask with class colorbar\n",
    "    :param img: 3D ndarray of input image\n",
    "    :param remapped_mask: 2D/3D ndarray of input segmentation mask with class ids\n",
    "    :param remapped_colormap: dictionary that indicates color corresponding to each class\n",
    "    :param classes_exp: dictionary of classes names and corresponding class ids\n",
    "    :param experiment: experimental setup\n",
    "    :return: plot of image and rgb mask with class colorbar\n",
    "    \"\"\"\n",
    "    mask_rgb = mask_to_colormap(remapped_mask, colormap=remapped_colormap)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(26, 7))\n",
    "    plt.subplots_adjust(left=1 / 16.0, right=1 - 1 / 16.0, bottom=1 / 8.0, top=1 - 1 / 8.0)\n",
    "    axs[0].imshow(img)\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    img_u_labels = np.unique(remapped_mask)\n",
    "    c_map = []\n",
    "    cl = []\n",
    "    for i_label in img_u_labels:\n",
    "        for i_key, i_color in remapped_colormap.items():\n",
    "            if i_label == i_key:\n",
    "                c_map.append(i_color)\n",
    "        for i_key, i_class in classes_exp.items():\n",
    "            if i_label == i_key:\n",
    "                cl.append(i_class)\n",
    "    cl = np.asarray(cl)\n",
    "    cmp = np.asarray(c_map) / 255\n",
    "    cmap_mask = LinearSegmentedColormap.from_list(\"seg_mask_colormap\", cmp, N=len(cmp))\n",
    "    im = axs[1].imshow(mask_rgb, cmap=cmap_mask)\n",
    "    intervals = np.linspace(0, 255, num=len(cl) + 1)\n",
    "    ticks = intervals + int((intervals[1] - intervals[0]) / 2)\n",
    "    divider = make_axes_locatable(axs[1])\n",
    "    cax1 = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar1 = fig.colorbar(mappable=im, cax=cax1, ticks=ticks, orientation=\"vertical\")\n",
    "    #cbar1.ax.set_yticklabels(cl)\n",
    "    axs[1].axis(\"off\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def remap_experiment1(mask):\n",
    "    \"\"\"Remap mask for Experiment I\"\"\"\n",
    "    class_remapping_exp = {\n",
    "        0: [0],\n",
    "        1: [1],\n",
    "        2: [2],\n",
    "        3: [3],\n",
    "        4: [4],\n",
    "        5: [5],\n",
    "        6: [6],\n",
    "        7: [\n",
    "            7,\n",
    "            8,\n",
    "            9,\n",
    "            10,\n",
    "            11,\n",
    "            12,\n",
    "            13,\n",
    "            14,\n",
    "            15,\n",
    "            16,\n",
    "            17,\n",
    "            18,\n",
    "            19,\n",
    "            20,\n",
    "            21,\n",
    "            22,\n",
    "            23,\n",
    "            24,\n",
    "            25,\n",
    "            26,\n",
    "            27,\n",
    "            28,\n",
    "            29,\n",
    "            30,\n",
    "            31,\n",
    "            32,\n",
    "            33,\n",
    "            34,\n",
    "            35,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    classes_exp = {\n",
    "        0: \"Pupil\",\n",
    "        1: \"Surgical Tape\",\n",
    "        2: \"Hand\",\n",
    "        3: \"Eye Retractors\",\n",
    "        4: \"Iris\",\n",
    "        5: \"Skin\",\n",
    "        6: \"Cornea\",\n",
    "        7: \"Instrument\",\n",
    "    }\n",
    "\n",
    "    colormap = get_remapped_colormap(class_remapping_exp)\n",
    "    remapped_mask = remap_mask(mask, class_remapping=class_remapping_exp)\n",
    "    return remapped_mask#, classes_exp, colormap\n",
    "\n",
    "def remap_experiment2(mask):\n",
    "    \"\"\"Remap mask for Experiment II\"\"\"\n",
    "    class_remapping_exp = {\n",
    "        0: [0],\n",
    "        1: [1],\n",
    "        2: [2],\n",
    "        3: [3],\n",
    "        4: [4],\n",
    "        5: [5],\n",
    "        6: [6],\n",
    "        7: [7, 8, 10, 27, 20, 32],\n",
    "        8: [9, 22],\n",
    "        9: [11, 33],\n",
    "        10: [12, 28],\n",
    "        11: [13, 21],\n",
    "        12: [14, 24],\n",
    "        13: [15, 18],\n",
    "        14: [16, 23],\n",
    "        15: [17],\n",
    "        16: [19],\n",
    "        255: [25, 26, 29, 30, 31, 34, 35],\n",
    "    }\n",
    "\n",
    "    classes_exp = {\n",
    "        0: \"Pupil\",\n",
    "        1: \"Surgical Tape\",\n",
    "        2: \"Hand\",\n",
    "        3: \"Eye Retractors\",\n",
    "        4: \"Iris\",\n",
    "        5: \"Skin\",\n",
    "        6: \"Cornea\",\n",
    "        7: \"Cannula\",\n",
    "        8: \"Cap. Cystotome\",\n",
    "        9: \"Tissue Forceps\",\n",
    "        10: \"Primary Knife\",\n",
    "        11: \"Ph. Handpiece\",\n",
    "        12: \"Lens Injector\",\n",
    "        13: \"I/A Handpiece\",\n",
    "        14: \"Secondary Knife\",\n",
    "        15: \"Micromanipulator\",\n",
    "        16: \"Cap. Forceps\",\n",
    "        255: \"Ignore\",\n",
    "    }\n",
    "    colormap = get_remapped_colormap(class_remapping_exp)\n",
    "    remapped_mask = remap_mask(mask, class_remapping=class_remapping_exp)\n",
    "    return remapped_mask#, classes_exp, colormap\n",
    "\n",
    "def plot_experiment1(img, mask):\n",
    "    \"\"\"\n",
    "    Function for plotting of mask for Experiment I\n",
    "    :param img: 3D ndarray of input image\n",
    "    :param mask: 2D/3D ndarray of input segmentation mask with class ids\n",
    "    :return: plot of image and rgb mask with class colorbar\n",
    "    \"\"\"\n",
    "\n",
    "    remapped_mask = remap_experiment1(mask)\n",
    "    return plot_images(img, remapped_mask, colormap, classes_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52639a",
   "metadata": {
    "id": "bc1c1585"
   },
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    \"\"\"\n",
    "    Class that calculates the confusion matrix.\n",
    "    It keeps track of computed confusion matrix\n",
    "    until it has been reseted. \n",
    "    The ignore label should always be >= num_classes\n",
    "    :param num_classes: [int] Number of classes\n",
    "    :param: confusion_matrix: 2D ndarray of confusion_matrix\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.confusion_matrix = np.zeros((self.num_classes, self.num_classes))\n",
    "\n",
    "    def reset(self):\n",
    "        self.confusion_matrix = np.zeros((self.num_classes, self.num_classes))\n",
    "\n",
    "    def get_confusion_matrix(self):\n",
    "        \"\"\"\n",
    "        Returns confusion matrix\n",
    "        :return: confusion_matrix: 2D ndarray of confusion_matrix\n",
    "        \"\"\"\n",
    "        return self.confusion_matrix\n",
    "\n",
    "    def update_confusion_matrix(self, gt_mask, pre_mask):\n",
    "        \"\"\"\n",
    "        Calculates the confusion matrix for a given ground truth\n",
    "        and predicted segmentation mask and updates it\n",
    "        :param gt_mask: 2D ndarray of ground truth segmentation mask\n",
    "        :param pre_mask: 2D ndarray of predicted segmentation mask\n",
    "        :return: confusion_matrix: 2D ndarray of confusion_matrix\n",
    "        \"\"\"\n",
    "        assert gt_mask.shape == pre_mask.shape, f\" {gt_mask.shape} == {pre_mask.shape}\"\n",
    "\n",
    "        mask = (gt_mask >= 0) & (gt_mask < self.num_classes)\n",
    "        label = self.num_classes * gt_mask[mask].astype(\"int\") + pre_mask[mask].astype(\"int\")\n",
    "        count = np.bincount(label, minlength=self.num_classes ** 2)\n",
    "        self.confusion_matrix += count.reshape(self.num_classes, self.num_classes)\n",
    "        return self.confusion_matrix\n",
    "\n",
    "\n",
    "def pixel_accuracy(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates mean intersection over union given\n",
    "    the confusion matrix of ground truth and predicted\n",
    "    segmentation masks\n",
    "    :param confusion_matrix: 2D ndarray of confusion_matrix\n",
    "    :return: acc: [float] pixel accuracy\n",
    "    \"\"\"\n",
    "    acc = np.diag(confusion_matrix).sum() / confusion_matrix.sum()\n",
    "    return acc\n",
    "\n",
    "\n",
    "def pixel_accuracy_class(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates pixel accuracy per class given\n",
    "    the confusion matrix of ground truth and predicted\n",
    "    segmentation masks\n",
    "    :param confusion_matrix: 2D ndarray of confusion_matrix\n",
    "    :return: acc: [float] mean pixel accuracy per class\n",
    "    \"\"\"\n",
    "    acc = np.diag(confusion_matrix) / confusion_matrix.sum(axis=1)\n",
    "    acc = np.nanmean(acc)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def mean_intersection_over_union(confusion_matrix):\n",
    "    \"\"\"\n",
    "    Calculates mean intersection over union given\n",
    "    the confusion matrix of ground truth and predicted\n",
    "    segmentation masks\n",
    "    :param confusion_matrix: 2D ndarray of confusion_matrix\n",
    "    :return: miou: [float] mean intersection over union\n",
    "    \"\"\"\n",
    "    miou = np.diag(confusion_matrix) / (\n",
    "            np.sum(confusion_matrix, axis=1) + np.sum(confusion_matrix, axis=0) - np.diag(confusion_matrix)\n",
    "        )\n",
    "    miou = np.nanmean(miou)\n",
    "    return miou\n",
    "\n",
    "\n",
    "def segmentation_metrics(gt_masks, pred_masks, num_classes):\n",
    "    \"\"\"\n",
    "    Calculates segmentation metrics (pixel accuracy, pixel accuracy per class,\n",
    "    and mean intersection over union) for a list of ground truth and predicted\n",
    "    segmentation masks for a given number of classes\n",
    "    :param gt_masks: [list] 2D ndarray of ground truth segmentation masks\n",
    "    :param pred_masks: [list] 2D ndarray of predicted segmentation masks\n",
    "    :param num_classes: [int] Number of classes\n",
    "    :return: pa, pac, miou [float, float, float]: metrics\n",
    "    \"\"\"\n",
    "    assert len(gt_masks) == len(pred_masks)\n",
    "    confusion_matrix = ConfusionMatrix(num_classes=num_classes)\n",
    "\n",
    "    for gt_mask, pred_mask in zip(gt_masks, pred_masks):\n",
    "        confusion_matrix.update_confusion_matrix(gt_mask, pred_mask)\n",
    "\n",
    "    cm = confusion_matrix.get_confusion_matrix()\n",
    "    pa = pixel_accuracy(cm)\n",
    "    pac = pixel_accuracy_class(cm)\n",
    "    miou = mean_intersection_over_union(cm)\n",
    "    return pa, pac, miou\n",
    "\n",
    "\n",
    "def segmentation_metrics_task1(gt_masks, pred_masks):\n",
    "    \"\"\"\n",
    "    Calculates segmentation metrics (pixel accuracy, pixel accuracy per class,\n",
    "    and mean intersection over union) for a list of ground truth and predicted\n",
    "    segmentation masks for Task 1\n",
    "    :param gt_masks: [list] 2D ndarray of ground truth segmentation masks\n",
    "    :param pred_masks: [list] 2D ndarray of predicted segmentation masks\n",
    "    :return: pa, pac and miou: [float, float, float] metrics\n",
    "    \"\"\"\n",
    "    pa, pac, miou = segmentation_metrics(gt_masks=gt_masks,\n",
    "                                         pred_masks=pred_masks,\n",
    "                                         num_classes=8)\n",
    "    return pa, pac, miou\n",
    "\n",
    "\n",
    "def segmentation_metrics_task2(gt_masks, pred_masks):\n",
    "    \"\"\"\n",
    "    Calculates segmentation metrics (pixel accuracy, pixel accuracy per class,\n",
    "    and mean intersection over union) for a list of ground truth and predicted\n",
    "    segmentation masks for Task 2\n",
    "    :param gt_masks: [list] 2D ndarray of ground truth segmentation masks\n",
    "    :param pred_masks: [list] 2D ndarray of predicted segmentation masks\n",
    "    :return: pa, pac and miou: [float, float, float] metrics\n",
    "    \"\"\"\n",
    "    pa, pac, miou = segmentation_metrics(gt_masks=gt_masks,\n",
    "                                         pred_masks=pred_masks,\n",
    "                                         num_classes=17)\n",
    "    return pa, pac, miou\n",
    "\n",
    "\n",
    "def segmentation_metrics_task3(gt_masks, pred_masks):\n",
    "    \"\"\"\n",
    "    Calculates segmentation metrics (pixel accuracy, pixel accuracy per class,\n",
    "    and mean intersection over union) for a list of ground truth and predicted\n",
    "    segmentation masks for Task 3\n",
    "    :param gt_masks: [list] 2D ndarray of ground truth segmentation masks\n",
    "    :param pred_masks: [list] 2D ndarray of predicted segmentation masks\n",
    "    :return: pa, pac and miou: [float, float, float] metrics\n",
    "    \"\"\"\n",
    "    pa, pac, miou = segmentation_metrics(gt_masks=gt_masks,\n",
    "                                         pred_masks=pred_masks,\n",
    "                                         num_classes=25)\n",
    "    return pa, pac, miou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d8d56",
   "metadata": {
    "id": "15f36842"
   },
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "\n",
    "    CLASSES = ['pupil','surgical tape','hand','eye retractors','iris','skin','cornea','cannula','cap. cystotome','tissue forceps','primary knife','ph. handpiece','lens injector','i/a handpiece','secondary knife','micromanipulator','cap. forceps']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = remap_experiment2(cv2.imread(self.masks_fps[i], 0))\n",
    "        \n",
    "        # extract certain classes from mask \n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0317bfce",
   "metadata": {
    "id": "dFEyF8cQ80ia"
   },
   "outputs": [],
   "source": [
    "class_remapping_exp = {\n",
    "    0: [0],\n",
    "    1: [1],\n",
    "    2: [2],\n",
    "    3: [3],\n",
    "    4: [4],\n",
    "    5: [5],\n",
    "    6: [6],\n",
    "    7: [7, 8, 10, 27, 20, 32],\n",
    "    8: [9, 22],\n",
    "    9: [11, 33],\n",
    "    10: [12, 28],\n",
    "    11: [13, 21],\n",
    "    12: [14, 24],\n",
    "    13: [15, 18],\n",
    "    14: [16, 23],\n",
    "    15: [17],\n",
    "    16: [19],\n",
    "    255: [25, 26, 29, 30, 31, 34, 35],\n",
    "}\n",
    "\n",
    "classes_exp = {\n",
    "    0: \"Pupil\",\n",
    "    1: \"Surgical Tape\",\n",
    "    2: \"Hand\",\n",
    "    3: \"Eye Retractors\",\n",
    "    4: \"Iris\",\n",
    "    5: \"Skin\",\n",
    "    6: \"Cornea\",\n",
    "    7: \"Cannula\",\n",
    "    8: \"Cap. Cystotome\",\n",
    "    9: \"Tissue Forceps\",\n",
    "    10: \"Primary Knife\",\n",
    "    11: \"Ph. Handpiece\",\n",
    "    12: \"Lens Injector\",\n",
    "    13: \"I/A Handpiece\",\n",
    "    14: \"Secondary Knife\",\n",
    "    15: \"Micromanipulator\",\n",
    "    16: \"Cap. Forceps\",\n",
    "    255: \"Ignore\",\n",
    "}\n",
    "\n",
    "colormap = get_remapped_colormap(class_remapping_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a420e2",
   "metadata": {
    "id": "f671d692"
   },
   "outputs": [],
   "source": [
    "import albumentations as albu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b833e54",
   "metadata": {
    "id": "6303a959"
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        albu.PadIfNeeded(min_height=320, min_width=320, always_apply=True, border_mode=0),\n",
    "        albu.RandomCrop(height=320, width=320, always_apply=True),\n",
    "\n",
    "        albu.IAAAdditiveGaussianNoise(p=0.2),\n",
    "        albu.IAAPerspective(p=0.5),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.RandomBrightness(p=1),\n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.IAASharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(544, 960)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26510496",
   "metadata": {
    "id": "fd8ee430"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be573d7d",
   "metadata": {
    "id": "fa37e5fd"
   },
   "outputs": [],
   "source": [
    "ENCODER = 'se_resnext50_32x4d'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['pupil','surgical tape','hand','eye retractors','iris','skin','cornea','cannula','cap. cystotome','tissue forceps','primary knife','ph. handpiece','lens injector','i/a handpiece','secondary knife','micromanipulator','cap. forceps']\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentatioh\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd684676",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8a47243",
    "outputId": "91047714-86ce-420a-96dd-2cfedec6fa7e"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a90214",
   "metadata": {
    "id": "4de21c69"
   },
   "outputs": [],
   "source": [
    "# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "criterion =torch.nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d267fc",
   "metadata": {
    "id": "klTLkV_WBfjv"
   },
   "outputs": [],
   "source": [
    "weights = [0.028,0.028,0.088,0.028,0.290,0.036,0.214,0.038,4.520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbcb1d",
   "metadata": {
    "id": "bf14f218"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee891eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('./unet_BCE_exp2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc0919",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bd20a58f",
    "outputId": "4c34d8e9-309e-4e9f-ff24-8cb2da5d0194"
   },
   "outputs": [],
   "source": [
    "train_loss_values = []\n",
    "val_loss_values = []\n",
    "IoU_scores_train = {}\n",
    "IoU_scores_val = {}\n",
    "\n",
    "model.cuda()\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:   \n",
    "        for i, (inputs,labels) in enumerate(tepoch):\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()        \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,labels)\n",
    "\n",
    "            # backward propagation\n",
    "            loss.backward()\n",
    "\n",
    "            # update the gradient to new gradients\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "        else:\n",
    "            train_loss_values.append(train_loss/len(train_loader))\n",
    "            \n",
    "    val_loss = 0 \n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        with tqdm(valid_loader, unit=\"batch\") as tepoch2:\n",
    "            for inputs, labels in tepoch2:\n",
    "                tepoch2.set_description(f\"Epoch {epoch}\")\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                logps = model.forward(inputs)\n",
    "                loss = criterion(logps,labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                tepoch2.set_postfix(loss=loss.item())\n",
    "            else:\n",
    "                val_loss_values.append(val_loss/len(valid_loader))\n",
    "    \n",
    "    torch.save(model, './unet_BCE_exp2.pth')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500680b",
   "metadata": {
    "id": "481debf0"
   },
   "outputs": [],
   "source": [
    "model = torch.load('./unet_BCE_exp2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b62fce",
   "metadata": {
    "id": "231f3b56"
   },
   "outputs": [],
   "source": [
    "# create test dataset\n",
    "test_dataset = Dataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    augmentation=get_validation_augmentation(), \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451517af",
   "metadata": {
    "id": "3d6e8c31"
   },
   "outputs": [],
   "source": [
    "# test dataset without transformations for image visualization\n",
    "test_dataset_vis = Dataset(\n",
    "    x_test_dir, y_test_dir, \n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e09fe",
   "metadata": {
    "id": "9bab4930"
   },
   "outputs": [],
   "source": [
    "def one_mask(pr_mask):\n",
    "    mask = 0\n",
    "    for i in range(17):\n",
    "        mask += pr_mask[i,:,:]*(i+1)\n",
    "    mask = mask-1\n",
    "    mask[mask==-1] = 18\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d003639",
   "metadata": {
    "id": "3d425974"
   },
   "outputs": [],
   "source": [
    "from progressbar import ProgressBar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5d3e02",
   "metadata": {
    "id": "80b2e5c8"
   },
   "outputs": [],
   "source": [
    "best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8202cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "pas = {}\n",
    "pacs = {}\n",
    "ious = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61149fb",
   "metadata": {
    "id": "cedeccdc"
   },
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "for i in range(17):\n",
    "    gt_masks = {}\n",
    "    pr_masks = {}\n",
    "    pbar = ProgressBar()\n",
    "    for n in pbar(range(100)):\n",
    "\n",
    "        image, gt_mask = test_dataset[n]\n",
    "\n",
    "        gt_mask = gt_mask.squeeze()\n",
    "\n",
    "        x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0).float()\n",
    "        pr_mask = best_model.predict(x_tensor)\n",
    "        pr_mask = pr_mask.squeeze().cpu().numpy().round()\n",
    "\n",
    "        if i in gt_masks.keys():\n",
    "            gt_masks[i].append(gt_mask[i])\n",
    "        else:\n",
    "            gt_masks[i] = [gt_mask[i]]\n",
    "\n",
    "        if i in pr_masks.keys():\n",
    "            pr_masks[i].append(pr_mask[i])\n",
    "        else:\n",
    "            pr_masks[i] = [pr_mask[i]]\n",
    "    pa,pac,iou = segmentation_metrics(gt_masks[i], pr_masks[i],2)\n",
    "    ious[i] = iou\n",
    "    pas[i] = pa\n",
    "    pacs[i] = pac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11be52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01563a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978fc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(ious.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0064eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(pas.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f80061",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(pacs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fc4b8",
   "metadata": {
    "id": "d74c14a3"
   },
   "outputs": [],
   "source": [
    "\n",
    "n = np.random.choice(len(test_dataset))\n",
    "image_vis = test_dataset_vis[250][0].astype('uint8')\n",
    "image, gt_mask = test_dataset[250]\n",
    "\n",
    "gt_mask = one_mask(gt_mask.squeeze())\n",
    "\n",
    "x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0).float()\n",
    "pr_mask = best_model.predict(x_tensor)\n",
    "pr_mask = one_mask(pr_mask.squeeze().cpu().numpy().round())\n",
    "gt_mask = mask_to_colormap(gt_mask, colormap)\n",
    "pr_mask = mask_to_colormap(pr_mask, colormap)\n",
    "\n",
    "visualize(\n",
    "image=image_vis, \n",
    "ground_truth_mask=gt_mask, \n",
    "predicted_mask=pr_mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbfe320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Unet_BCE_exp2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
